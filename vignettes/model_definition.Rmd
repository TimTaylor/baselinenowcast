---
title: "Mathematical methods for `baselinenowcast`"
description: "Description of mathematical methods used in the package"
output:
  bookdown::html_document2:
    fig_caption: yes
    code_folding: show
pkgdown:
  as_is: true
bibliography: library.bib
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa-numeric-superscript-brackets.csl
link-citations: true
vignette: >
  %\VignetteIndexEntry{Mathematical methods for baselinenowcast}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Overview

The `baselinenowcast` model was originally conceived as a reference model for the nowcasting challenge described in [Wolffram et al.](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011394). The method is based entirely on preliminary case counts assigned to reference times and report times, to create what we will refer to as a reporting triangle. The model is based on the assumption that the empirically observed distribution of delays in past data can be propagated forward to estimate the expected case counts that have yet to be observed. This iterative process of propagating the partially observed case counts forward in time using an empirical delay distribution estimate is often referred to as a multiplicative model. The `baselinenowcast` method allows for flexibility in how these components are combined. The delay distribution can be estimated directly from the reporting triangle that is being "completed", or it can be estimated from complete past data, or data from a different strata or setting. From a delay estimate and a reporting triangle, the multiplicative model is used to generate point estimates of case counts at reference times and delays, essentially "filling in" the reporting triangle to create what we will refer to as a point nowcast.

`baselinenowcast` generates probabilistic nowcasts using past nowcast errors, assuming a negative binomial observation model. Again, the user has the flexibility to estimate the dispersion parameters of the negative binomial either using the reporting triangle being nowcasted, or using external data either entirely from the past or from other strata. Expected observed counts at each reference time and report time are generated by sampling from a negative binomial with mean given by the point nowcast and dispersion parameter estimated from past nowcast errors, as described above.

## Notation

We denote $X_{t,d}, d = 0, .., D$ as the number of cases occurring on time $t$ which appear in the dataset with a delay of $d$. For example, a delay $d = 0$ means that a case occurring on day $t$ arrived in the dataset on day $t$, or on what is considered to be the first possible report date in practice. We only consider cases reporting within a maximum delay $D$. The number of cases reporting for time $t$ with a delay of at most $d$ can be written as:

$$X_{t, \le d} = \sum_{i=0}^d X_{t,i} $$

Such that $X_t = X_{t, \le D}$ is the “final” number of reported cases on time $t$. Conversely, for $d < D$

$$X_{t,>d} = \sum_{i = d+1} ^{D} X_{t,i}$$

is the number of cases still missing after $d$ delay. We refer to $X_t$ to describe a random variable, $x_t$ for the corresponding observation, and $\hat{x}_t$ for an estimated/imputed value. The matrix of $x_{t,d}$ available at a given data release time $t^*$ is referred to as the reporting triangle. Here, all $t+d>t^*$ have yet to be observed.

|   | $d = 0$ | $d = 1$ | $d=2$ | $...$ | $d= D-1$ | $d= D$ |
|-----------|-----------|-----------|-----------|-----------|-----------|-----------|
| $t=1$ | $x_{1,0}$ | $x_{1,1}$ | $x_{1,2}$ | $...$ | $x_{1,D-1}$ | $x_{1, D}$ |
| $t=2$ | $x_{2,0}$ | $x_{2,1}$ | $x_{2,2}$ | $...$ | $x_{2,D-1}$ | $x_{2, D}$ |
| $t=3$ | $x_{3,0}$ | $x_{3,1}$ | $x_{3,2}$ | $...$ | $x_{3,D-1}$ | $x_{3, D}$ |
| $...$ | $...$ | $...$ | $...$ | $...$ | $...$ | $...$ |
| $t=t^*-1$ | $x_{t^*-1,0}$ | $x_{t^*-1,1}$ | $x_{t^*-1,,2}$ | $...$ | $x_{t^*-1,,D-1}$ | $x_{t^*-1,D}$ |
| $t=t^*$ | $x_{t^*,0}$ | $x_{t^*,1}$ | $x_{t^*,2}$ | $...$ | $x_{t^*,D-1}$ | $x_{t^*, D}$ |

We refer to the matrix with imputed values for all $t+d>t^*$ as a point nowcast, and the matrix with a complete set of observations for all elements as a complete reporting square.

# Point estimate of the delay distribution

The `get_delay_estimate()` function

## Estimate of the delay distribution from a complete reporting square

We can use a complete reporting square (which can in reality, be rectangular) to compute an empirical estimate of the delay distribution, $\pi(d)$. The empirical delay distribution, $\pi(d)$ can be computed directly from the completed reporting square $X$

$$
\pi(d)= \frac{\sum_{t=1}^{t=t^*} X_{t,d}}{\sum_{d=0}^{D} \sum_{t=1}^{t=t^*} X_{t,d}}
$$

Where the numerator is the sum of all the observations across reference times $t$ for a particular delay $d$, and the denominator is the sum across all reference times $t$ and delays $d$.

The `get_delay_estimate()` function ingests a complete reporting square and uses the last $n$ rows to compute an empirical delay probability mass function (returning a simplex vector indexed starting at delay 0).

## Estimate of the delay distribution from a reporting triangle

In the case where we have missing values in the bottom right of the reporting triangle, we need to use the multiplicative model to generate a matrix containing a mixture of observed and imputed values. Then we can compute the delay distribution as described above for the complete reporting square case.

The multiplicative model works by iteratively "filling in" the reporting triangle starting from the bottom left, and moving column by column from left to right until the bottom right of the triangle is filled in.

![](../man/figures/schematic_fig.png)

Figure 1. Visual description of the iterative “completing” of the reporting triangle, moving from left to right and bottom to top. In this cases, we are imputing $x_{t=6, d = 2}$ and $x_{t=5, d= 2}$ assuming that the ratio between $x_{t=1:4, d = 2}$ (block top), and \$x\_{t=1:4, d = 0:1} \$ (block top left) holds for for $x_{t=5:6, d = 2}$ (block bottom) and $x_{t=5:6, d = 0:1}$ (block bottom left). In this example, $x_{t=6, d = 1}$ has already been imputed using the same approach, and we treat it as known going forward. This process is repeated across the reporting triangle to estimate all values shown in the dashed lines.

The method requires at least one observation, at delay $d=0$ for the most recent reference time, located at the bottom of the reporting triangle in Fig 1 above. The method assumes that the values at each delay $d$ for the recent times $t$, will consist of the same proportion of the values previously reported for earlier times $t$. To fill in the missing values for each column $d$, we sum over the rectangle of completely observed reference dates for all $d-1$ columns (block top left) and sum over the column of completely observed reference dates for all of the entries in column $d$ (block left). The ratio of these two sums is assumed to be the same in the missing entries in column $d$, so we use the entries observed up to $d-1$ for each incomplete reference date (block bottom left), and scale by this ratio to get the missing entries in column $d$. This process is repeated for each delay from $d$ to the maximum delay $D$. At each iteration an additional reference time entry is computed as the delay $d$ increases.

The `get_delay_estimate()` function ingests a reporting triangle and uses the last $n$ rows to compute an empirical delay probability mass function (returning a simplex vector indexed starting at delay 0).

# Generation of a point nowcast from a delay distribution and a non-complete reporting triangle

To propagate the point nowcast from the delay distribution, we need to estimate the expected total number of eventual observed cases $\hat{x}_t$, for each reference time $t$.
Let $z$ be the sum over all delays $d$ that have already been observed (up until $t^*-t$), such that $z =\sum_{d=1}^{d=t^*-t} x_{t,d}$ and $\delta$ be the cumulative sum of the delay distribution, $\pi(d)$ up until $d = t^*-t$ such that $\delta = \sum_{d=1}^{d=t^*-t} \pi(d)$.
By assuming that $z \sim Bin(x_t, \delta)$ and $x_t \sim Unif(0, \inf)$, it can be shown that the expected value of $x_t$, the total number of reported cases on reference time $t$, can be written as:

$$
E(x_t | z, \delta) = \hat{x}_t = \frac{z + 1 - \delta}{\delta}
$$

Then we can compute $\hat{x}_{t,d}$ directly using the $d$th element of $\pi(d)$

$$
\hat{x}_{t,d} = \pi(d) \times \hat{x}_t
$$

Where the number of reports at timepoint $t$ with delay $d$ is the product of the the expected total reports, $x_t$ and the proportion expected at that particular delay $d$, $\pi(d)$.

The `apply_delay()` function ingests a reporting triangle and a delay PMF and returns a point nowcast.

# Estimate of dispersion

To estimate the uncertainty in the nowcasts, we use past nowcast errors and assume a negative binomial observation model.

## Generation of retrospective reporting triangles

We describe a method which generates retrospective reporting triangles to replicate what would have been available as of time $t^*=s^*$, where $s^* = t^*-m$ for $m = 1, 2, ... M$ to generate $M$ retrospective reporting triangles.

To generate the set of $M$ reporting triangles, we simply remove the last $m$ rows of the existing reporting triangle (or reporting square/rectangle), to generate $M$ truncated partially complete reporting triangles.
These can be generated from a reporting triangle or square with the function `truncate_triangles()` which returns a list of `n` truncated triangles containing only observations and missing values.
We then replace the bottom right triangle of each matrix with NAs, assuming these would not have been observed as of $s^*$, using the function `generate_triangles()` which returns a list of $n$ retrospective reporting triangles.
The method uses each retrospective reporting triangle to re-estimate a delay distribution using the $N$ preceding rows of the reporting triangle before $s^*$, and recomputes a retrospective nowcast, for $M$ realizations of the retrospective reporting triangle (so $M$ different $s^*$ values).

## Generation of retrospective point nowcasts

From the $M$ reporting triangles, we apply the method described above to estimate a delay distribution from a reporting triangle and generate a point nowcast for each reporting triangle, to generate $M$ point nowcasts.
The function `generate_point_nowcasts()` ingests the list of reporting triangles, estimates a delay distribution for each, and generates a set of point nowcasts.

## Fit point nowcasts and observed values to a negative binomial observation model at each delay

We then take the set of point nowcasts, and the set of truncated partially complete reporting triangles (these do not necessarily contains NAs on the bottom right, the bottom right could be entirely or partially observed). For each delay $d$ we identify the overlapping set of matrix elements that were imputed retrospectively and matrix elements that had been observed as of the most recent time point.

For each delay $d = 1, ..., D$ we assume that the observed values, $X_{s^*-d, >d}$ follow a negative binomial observation model with a mean of $\hat{x}_{s^*-d}$:

$$
X_{s^*-d,>d} | \hat{x}_{s^*-d, >d}(s*) \sim NegBin(\mu = \hat{x}_{s^*-d} + 0.1, \phi = \phi_d)
$$

We add a small number (0.1) to the mean to avoid an ill-defined negative binomial. We note that to perform all these computations, data snapshots from at least $N + M$ past observations, or rows of the reporting triangle, are needed. This estimate of the uncertainty accounts for the empirical uncertainty in the point estimate of the delay distribution over time.

The function `estimate_dispersion()` ingests a list of truncated triangles representing the observations, and the list of point nowcasts, and returns a vector of negative binomial dispersion parameters indexed starting at delay $d$.

# Generate a probabilistic nowcast

Using the dispersion parameters for each delay, $\phi(d)$ for $d = 1,...D$, we can generate probabilistic nowcasts by drawing samples from the negative binomial:

$$
X_{t,d} \sim NegBin(\mu = \hat{x}_{t,d}, \phi = \phi(d))
$$

We can sample for any number of draws, and then use the draws to compute any desired quantiles to summarize the outputs.

The function `add_obs_errors_to_nowcast()` ingests a point nowcast, the dispersion parameters, and the number of draws to sample and generates a list of expected observed point nowcasts.
This can then be summarized across delays by passing the list to `nowcast_list_to_df()` and summarised by reference time using `summarise_by_ref_time()`.
